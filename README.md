# Computer-Vision-Projects

**Author:** Rhishi Kumar Ayyappan

---

## Portfolio Overview

A curated collection of production-grade, business-impactful Computer Vision projects. Each project tackles a real-world visual challenge using state-of-the-art AI pipelines, from-scratch model implementation, and clear metrics focused on business value—ready for recruiters and hiring managers.

---

## Projects

### 1. Custom Object Detection Pipeline (YOLOv8 & Gradio)

**Challenge:** Businesses need to rapidly train and deploy custom object detectors for specific tasks (e.g., safety gear, product counting, defect identification) without a lengthy development cycle.

**Impact:** Provides a reusable, end-to-end pipeline that cuts development time from weeks to days. Deployed a live Gradio web app for immediate, tangible stakeholder feedback and model validation.

**Highlights:** YOLOv8, mAP50 of 0.954 (on COCO128), full training/validation analysis, robust data pipeline, and an interactive Gradio web app deployment.

**[See the project folder for full details](https://github.com/rhishikumarayyappan/Computer-Vision-Projects/tree/main/CV_YOLOv8_Custom_Object_Detection)**

---

### 2. Semantic Segmentation from Scratch (U-Net)

**Challenge:** Automating the slow, expensive, and subjective manual process of pixel-level annotation (segmentation) for tasks in medical, satellite, or e-commerce imagery.

**Impact:** Built the U-Net architecture from scratch, creating a foundational framework that can automate thousands of hours of manual labor and enable precise quantitative analysis (e.g., measuring the *exact area* of a tumor or defect).

**Highlights:** U-Net built from scratch (Keras Functional API), Oxford-IIIT Pet dataset, robust `tf.data` pipeline, high-accuracy pixel-level predictions, and clear validation/loss curve analysis.

**[See the project folder for full details](https://github.com/rhishikumarayyappan/Computer-Vision-Projects/tree/main/CV_U_Net_for_Image_Segmentation)**

---

### 3. Image Captioning with a Custom Transformer

**Challenge:** Automatically generating descriptive alt-text and captions to make web content accessible (WCAG compliant), searchable (SEO-friendly), and engaging at scale.

**Impact:** Deployed a model that automates WCAG accessibility and improves e-commerce/Digital Asset Management (DAM) searchability. This project demonstrates a deep, fundamental understanding of modern attention-based architectures.

**Highlights:** Transformer Decoder built from scratch, EfficientNetB0 encoder (transfer learning), Flickr8k dataset, generates contextually accurate and human-like captions from raw images.

**[See the project folder for full details](https://github.com/rhishikumarayyappan/Computer-Vision-Projects/tree/main/CV_Image%20_Captioning%20_with_Transformers)**

---

## Business Impact & Metrics

All projects report key performance metrics (e.g., mAP, validation accuracy) and clear visualizations.
Each folder details the specific business value, from automating manual labor to creating interactive demos and ensuring accessibility compliance.
Every project includes best practices: a clean README, a requirements list, visualizations, and reproducible code.

---

## How to Use

Browse each project folder for its detailed README, code, outputs, and key results.
Install and run using the instructions in each project’s README.
Visualizations and metric reports are included in every folder for recruiter-ready review.

---

## Tech Highlights

-   **Python**
-   **TensorFlow & Keras** (Functional & Subclassing APIs)
-   **PyTorch**
-   **Ultralytics YOLOv8**
-   **Transformers** (Attention Mechanisms built from scratch)
-   **EfficientNet** (Transfer Learning)
-   **Gradio** (Interactive Web Demos)
-   **TensorFlow Datasets (TFDS)**
-   **Matplotlib & Seaborn** (Data Visualization)
-   **Google Colab** (GPU-Accelerated Training)

---

**Portfolio designed for clarity, business value, and technical depth.**
**Contact for further details or demo requests!**
